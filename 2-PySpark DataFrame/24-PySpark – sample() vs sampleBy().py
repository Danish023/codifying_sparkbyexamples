# PySpark provides a pyspark.sql.DataFrame.sample(), pyspark.sql.DataFrame.sampleBy(), RDD.sample(), and
# RDD.takeSample() methods to get the random sampling subset from the large dataset

# If you are working as a Data Scientist or Data analyst you are often required to analyze a large dataset/file with
# billions or trillions of records, processing these large datasets takes some time hence during the analysis phase
# it is recommended to use a random subset sample from the large files.

# https://sparkbyexamples.com/pyspark/pyspark-sampling-example/